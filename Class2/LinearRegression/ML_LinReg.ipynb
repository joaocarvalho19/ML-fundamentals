{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 – Linear Regression\n",
    "## PART 1 Univariable Linear Regression\n",
    "\n",
    "Objectives: Implement linear regression with one variable (feature) and get to see it works on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the lab work you will implement Univariate Linear Regression to predict profits for a food truck (a large vehicle equipped to cook and sell food). Suppose you are the CEO of a restaurant franchise and consider different cities for opening a new food truck. The chain already has trucks in various cities and you have data for profits and populations from the cities. You would like to use this data to help you select in which city to expand your business.\n",
    "\n",
    "First, import all relevant libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Plot the Data. \n",
    "\n",
    "The file *Uni_linear.txt* contains the dataset for the Linear Regression problem. The first column is the population of a city (variable X) and the second column is the profit of a food truck in that city (variable y). The values are scaled: number of people/10000 and profit in dolars/10000. A negative value for profit indicates a loss. \n",
    "\n",
    "Load data into the variable **data** (using function pd.read_csv from panda library).\n",
    "\n",
    "Create a scatter plot of data similar to Fig.1 (using plt.scatter). \n",
    "\n",
    "<img src=\"images/f1.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig. 1** : **file Uni_linear.txt** </center></caption>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.read_csv(?, ?)\n",
    "data = pd.read_csv(\"Uni_linear.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.8233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1\n",
       "0  6.1101  17.5920\n",
       "1  5.5277   9.1302\n",
       "2  8.5186  13.6620\n",
       "3  7.0032  11.8540\n",
       "4  5.8598   6.8233"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a few examples from the dataset \n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.159800</td>\n",
       "      <td>5.839135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.869884</td>\n",
       "      <td>5.510262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.026900</td>\n",
       "      <td>-2.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.707700</td>\n",
       "      <td>1.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.589400</td>\n",
       "      <td>4.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.578100</td>\n",
       "      <td>7.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.203000</td>\n",
       "      <td>24.147000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1\n",
       "count  97.000000  97.000000\n",
       "mean    8.159800   5.839135\n",
       "std     3.869884   5.510262\n",
       "min     5.026900  -2.680700\n",
       "25%     5.707700   1.986900\n",
       "50%     6.589400   4.562300\n",
       "75%     8.578100   7.046700\n",
       "max    22.203000  24.147000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some statistics\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2717dd2f550>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create Fig. 1  (using plt.scatter)\n",
    "plt.scatter(data[0], data[1])\n",
    "#Add labels : plt.xlabel; plt.ylabel; plt.title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the Cost Function $J(\\theta)$\n",
    "\n",
    "The objective of Linear Regression is to minimize the cost function: $J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)} )^2$\n",
    "\n",
    "where the hypothesis *h* is given by the linear model: $h_\\theta(x)=\\theta^Tx=\\theta_0+\\theta_1x_1$ \n",
    "\n",
    "Your task is to complete the function **computeCost(X,y,theta)**.  Remember that the variables X and y are not scalar values, X is an array (matrix) with dimension (*mx2*), y is an array (vector) with dimension (*mx1*), *m* rows represent the examples from the training set.\n",
    "\n",
    "Suggestion: Use the vectorized dot product with *np.dot()* to generate *h*. \n",
    "Use *np.sum()* to compute the sum of errors over all given examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(X,y,theta):\n",
    "    \"\"\"\n",
    "   Take the numpy arrays X, y, theta and return the cost function J for this theta. \n",
    "\n",
    "    \"\"\"\n",
    "    m=len(y)\n",
    "    h= np.dot(X, theta)\n",
    "    J= ( 1/(2*m) ) * np.sum((h-y)**2)\n",
    "\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will provide values for the arguments of **computeCost(X,y,theta)**. \n",
    "First, extract X and y from data. \n",
    "\n",
    "Check if X and y are rank 1 arrays (m,), and if yes, you need to reshape them to be 2-dimensonal arrays (m,1).  \n",
    "Each example is stored as a row.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.072733877455676"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n=data.values # extract only the values of the two columns from the dataFrame data\n",
    "X= data_n[:,0]\n",
    "y= data_n[:,1]\n",
    "\n",
    "X = X.reshape(m,1)\n",
    "y= y.reshape(m,1)\n",
    "\n",
    "\n",
    "m = X.shape[0]\n",
    "n = X.shape[1]\n",
    "#To take into account the intercept term theta_0 you need to add an additional first column to X and \n",
    "#set it to all ones (np.ones). #This allows to treat  theta_0 as simply another ‘feature parameter’. \n",
    "\n",
    "X=np.append(np.ones((m,1)),X,axis=1) \n",
    "\n",
    "#Initialize the fitting parameters theta to 0 (np.zeros)\n",
    "\n",
    "theta=np.zeros((n+1, 1))\n",
    "print(theta.shape)\n",
    "\n",
    "#You should see a cost of about 32.07.\n",
    "\n",
    "computeCost(X,y,theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Minimize the cost function $J(\\theta)$ by updating Equation        \n",
    "$\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$ (simultaneously update $\\theta_j$ for all $j$) and repeat unitil convergence. \n",
    "\n",
    "\n",
    "Implement gradient descent in the function **gradientDescent**. The loop structure is written, you need to supply the updates to $\\theta$  within each iteration.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(X,y,theta,alpha,num_iters):\n",
    "    \"\"\"\n",
    "    Take numpy arrays X, y and theta and update theta by taking num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "     Return: theta and the list of the cost of theta (J_history) during each iteration\n",
    "    \"\"\"\n",
    "    \n",
    "    m=len(y)\n",
    "    J_history=[]\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        h = np.dot(X, theta)\n",
    "        grad = np.dot(X.transpose(),(h-y)) #Vectorized way to compute all gradients simultaneously \n",
    "        theta = theta - (grad*alpha)\n",
    "        \n",
    "        J_history.append(computeCost(X,y,theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run  **gradientDescent** with learning rate alpha= 0.01 and 1500 iterations and get the final parameters $\\theta_0$ = -3.630, $\\theta_1$=1.166. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "[[nan]\n",
      " [nan]]\n",
      "h(x) =nan + nanx1\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.01\n",
    "num_iters = 1500\n",
    "theta,J_history = gradientDescent(X,y,theta,alpha,num_iters)\n",
    "\n",
    "print(\"h(x) =\"+str(round(theta[0,0],2))+\" + \"+str(round(theta[1,0],2))+\"x1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the Cost Function $J(\\theta)$ \n",
    "To understand the cost function $J(\\theta)$ better, we plot the cost in a 3D graph over a grid of values for $\\theta_0$ and $\\theta_1$. The cost function has a global minimum. This minimum is the optimal point for $\\theta_0$ and $\\theta_1$ and each step of gradient descent moves closer to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating values for theta0, theta1 and the resulting cost value\n",
    "theta0_vals=np.linspace(-10,10,100)\n",
    "theta1_vals=np.linspace(-1,4,100)\n",
    "J_vals=np.zeros((len(theta0_vals),len(theta1_vals)))\n",
    "\n",
    "for i in range(len(theta0_vals)):\n",
    "    for j in range(len(theta1_vals)):\n",
    "        t=np.array([theta0_vals[i],theta1_vals[j]])\n",
    "        J_vals[i,j]=computeCost(X,y,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the surface plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf=ax.plot_surface(theta0_vals,theta1_vals,J_vals,cmap=\"coolwarm\")\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.set_xlabel(\"$\\Theta_0$\")\n",
    "ax.set_ylabel(\"$\\Theta_1$\")\n",
    "ax.set_zlabel(\"$J(\\Theta)$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the implementation\n",
    "\n",
    "A good way to verify that gradient descent is working correctly is to plot $J(\\theta)$ against the number of iteration. Function **gradientDescent** calls function **computeCost** on every iteration and saves the costs over the iterations. If the algorithm works properly, $J(\\theta)$ should never increase, and should converge to a steady value. Plot the gradient history (use *plt.plot()*) and get a curve similar to Fig.2. \n",
    "\n",
    "<img src=\"images/f2.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig.2** : **$J(\\theta)$** </center></caption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(?)\n",
    "\n",
    "#Add labels : plt.xlabel; plt.ylabel; plt.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph with Best Line Fit \n",
    "\n",
    "Overlap data and the best line fit (with the optimized  $\\theta$ values) as shown in Fig.3. \n",
    "\n",
    "<img src=\"images/f3.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig. 3** : ** ** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data\n",
    "plt.scatter(?,?)\n",
    "\n",
    "#add the best line fit with red colour\n",
    "x_fit=range(25)\n",
    "y_fit=theta[0]+theta[1]*x_fit\n",
    "\n",
    "plt.plot(?,?,?)\n",
    "\n",
    "#Add labels : plt.xlabel; plt.ylabel; plt.title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions  using the optimized $\\theta$ values\n",
    "\n",
    "Complete function **predict** to compute model predictions: $h_\\theta(x) = X*theta$. Apply vectorized computations with np.dot(). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,theta):\n",
    "    \"\"\"\n",
    "    Takes in numpy array of x and theta and return the predicted value of y based on theta\n",
    "    \"\"\"\n",
    "    \n",
    "    h= ?\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run  **predict** to predict profits in areas of 35,000 and 70,000 people. Note that you need to scale the numbers properly !\n",
    "\n",
    "Answer: \n",
    "\n",
    "        For population = 35,000, predicted profit of 4520 USD\n",
    "\n",
    "        For population = 70,000, predicted profit of 45342 USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1= ?\n",
    "print(\"For population = 35,000, we predict a profit of $\"+str(np.round(predict1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2= ?\n",
    "print(\"For population = 70,000, we predict a profit of $\"+str(np.round(predict2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  PART 2 Multivariable Linear Regression\n",
    "Objectives: Implement linear regression with multiple variables (features) and get to see it works on data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will implement linear regression with multiple variables to predict the prices of houses. Suppose you are selling your house and you want to know what a good market price would be. One way to do this is to first collect information on recent houses sold and make a model of housing prices.\n",
    "\n",
    "The file **Multi_linear.txt** contains a training set of housing prices in Portland, Oregon. The first column is the size of the house (in square feet), the second column is the number of bedrooms, and the third column is the price of the house.  \n",
    "\n",
    "Load the data into the array data2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a few examples from the dataset \n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some statistics\n",
    "data2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Normalization\n",
    "\n",
    "Note that house sizes are much larger values (about 1000 times) than the number of bedrooms. When features differ by orders of magnitude, first performing feature scaling can make gradient descent converge much more quickly. \n",
    "To make sure features are on a similar scale apply Mean normalization.\n",
    "\n",
    "$x_i = \\frac{x_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "Your task is to complete the code in function **featureNormalization(X)**:\n",
    "\n",
    "• Compute the mean value  $\\mu_i$ of each feature (use np.mean(X,axis=0)) \n",
    "\n",
    "• compute the standard deviation $\\sigma_i$ of each feature (use np.std(X,axis=0)) \n",
    "\n",
    "• Apply the equation above.\n",
    "\n",
    "**Remark:** When normalizing the features, it is important to store the mean value and the standard deviation used for normalization. After optimizing the parameters of the model, you want to predict the price of a new example not seen before.\n",
    "You must first normalize the features of that new example using the mean and standard deviation previously computed from the training set.\n",
    "\n",
    "**Remark:** Mean normalization is an alternative to normalizing by making the absolute values < 1 (i.e. dividing by MaxValue-MinValue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNormalization(X):\n",
    "    \"\"\"\n",
    "    Take in numpy array of X values and return normalize X values,\n",
    "    the mean and standard deviation of each feature\n",
    "    \"\"\"\n",
    "    mean=?\n",
    "    std=?\n",
    "    \n",
    "    X_norm = ?\n",
    "    \n",
    "    return X_norm , mean , std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract from data2 the features in X2 and the output in y2. If rank 1, reshape them to have 2 dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n2=data2.values\n",
    "X2 =?\n",
    "y2=?\n",
    "\n",
    "#Run featureNormalization to normalize X2, store the means and stds.\n",
    "X2, mean_X2, std_X2 = ?\n",
    "\n",
    "#After normalizing the features add an extra column of 1's corresponding to x0 = 1. \n",
    "\n",
    "X2=np.append(.....)\n",
    "\n",
    "\n",
    "#Inicialize the vector of model parameters theta2 = 0.\n",
    "theta2= ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cost $J(\\theta)$\n",
    "In the previous (univariate) problem you have implemented the functions **computeCost** and **gradientDescent** in a vectorized way, therefore they will work for linear regression with any number of features. \n",
    "\n",
    "Answer: Cost = 65591548106.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeCost(X2,y2,theta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "\n",
    "\n",
    "Apply **gradientDescent** with different learning rates (e.g. alpha=[0.001, 0.01, 0.1, 0.3 1.4]) and 400 iterations.\n",
    "\n",
    "You may need to adjust the number of iterations in order to see well the overall trend in $J(\\theta)$ curve below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicialize theta2 = 0\n",
    "#theta2= ?\n",
    "theta2, J_history2 = gradientDescent(?,?,?,?,?)\n",
    "print(\"h(x) =\"+str(round(theta2[0,0],2))+\" + \"+str(round(theta2[1,0],2))+\"x1 + \"+str(round(theta2[2,0],2))+\"x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the Cost Function $J(\\theta)$\n",
    "\n",
    "If the learning rate is too small (e.g. 0.001), the gradient descent takes a very long time to converge to the optimal value. \n",
    "\n",
    "If the learning rate is too large (e.g. 1.4), $J(\\theta)$ can diverge and \"blow up\", resulting in values which are too large for computer calculations. In these situations, Python will return nan (not a number). This is often caused by undefined operations that involve +/- infinity.\n",
    "\n",
    "Get a similar plot as in Fig.4. \n",
    "\n",
    "<img src=\"images/f4.png\" style=\"width:350px;height:250px;\">\n",
    "<caption><center> **Fig. 4** Cost function for different learning rates ** ** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions using the optimized $\\theta$ values\n",
    "\n",
    "Using the best learning rate you found, run gradient descent until convergence to find the optimal $\\theta$ values.\n",
    "\n",
    "Predict the price of a house with 1650 square feet and 3 bedrooms (use function predict you have implemented in Part 1). \n",
    "\n",
    "Don't forget to normalize the features, before making this prediction!\n",
    "\n",
    "Answer: the price is about $293000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample =?\n",
    "#feature normalisation of x_sample\n",
    "x_sample= ?\n",
    "#add 1\n",
    "x_sample=\n",
    "predict3=predict(?,?)\n",
    "print(\"For size of house = 1650, Number of bedroom = 3, we predict a house value of $\"+str(round(predict3,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
