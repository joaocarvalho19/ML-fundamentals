{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab -  Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives**: implement Gaussian distribution model to detect anomalous behavior in server computers. \n",
    "\n",
    "While the servers were operating, 2D dataset regarding the through-put (mb/s) and latency (ms) of response of each server were collected. Vast majority of the examples were normal (non-anomalous) but also a few examples of servers acting anomalously.\n",
    "On that dataset you will ﬁt a Gaussian distribution and then ﬁnd values that have very low probability and hence can be considered anomalies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading relevant libraries and the dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=RuntimeWarning)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data \n",
    "Use loadmat to open file ex9data.mat and get train, test and validation data. Consult previous labs how to use loadmat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = ?\n",
    "Xtrain = ?  # only normal examples\n",
    "Xtest =? # normal and a few (6) abnormal examples\n",
    "Xval = ? # normal and a few (9) abnormal examples\n",
    "yval = ?\n",
    "\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot data\n",
    "\n",
    "Plot the scater plots of the data subsets (Xtrain,Xval, Xtest) and get figure similar to Fig. 1. \n",
    "\n",
    "<img src=\"images/im1.png\" style=\"width:600px;height:300px;\">\n",
    "<caption><center> **Fig. 1** : **Latency versus Throughput** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(?,?)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "?\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data\n",
    "\n",
    "Plot the histograms of each feature and get figure simular to Fig.2. \n",
    "\n",
    "\n",
    "<img src=\"images/im2.png\" style=\"width:300px;height:250px;\">\n",
    "<caption><center> **Fig. 1** : **Data distribution** </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(?, ?)\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Distribution\n",
    "\n",
    "To perform anomaly detection, you will first need to fit a model only to the normal data.\n",
    "\n",
    "Given a training set {x(1), …, x(m)} (where x(i) ∈ R^n, here n = 2), you want to estimate the Gaussian distribution for each of the features. For each feature (i = 1 . . . n), you need to find parameters mean and variance(mu, sigma²). For doing that let’s write down the function that calculates the mean and variance of matrix Xtrain.\n",
    "\n",
    "The Gaussian distribution is given by:  $p(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{\\frac{(x-\\mu)^2}{2\\sigma^2}}$\n",
    "\n",
    "mean:  $\\mu_i = \\frac{1}{m}\\sum^m_{j=1}x^{(j)}$\n",
    "\n",
    "variance:  $\\sigma^2_i = \\frac{1}{m}\\sum^m_{j=1}(x^{(j)} - \\mu_j)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateGaussian(X):\n",
    "    \"\"\"\n",
    "     This function estimates the parameters of a Gaussian distribution using the data in X\n",
    "    \"\"\"\n",
    "    m=?  #number of examples in X\n",
    "    \n",
    "    #compute mean \n",
    "    mu = ?\n",
    "     \n",
    "    # compute variance =sigma^2\n",
    "    sigma2 = 1/m * np.sum((X - mu)**2,axis=0)\n",
    "    \n",
    "    return mu,sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate parameters (mean and variance) for the Gaussian model of the normal data (Xtrain)\n",
    "# ANSWER:    mu =  [14.06411334 15.02441479] ; sigma2 = [0.93434723 0.8506542 ]\n",
    "\n",
    "mu, sigma2 = ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Gaussian Distribution\n",
    "\n",
    "Inside *multivariateGaussian*, $\\sigma^2$ vector is converted into the covariance matrix  $\\Sigma$.  Assuming the features are independent, each element of vector $\\sigma^2$ will be on the diagonal of matrix $\\Sigma$ and the rest of the elements are zero. \n",
    "Then the formula for the multivariate distribution to get the probability vector is applied.\n",
    "\n",
    "$p(x;\\mu,\\Sigma) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}} exp(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the function\n",
    "def multivariateGaussian(X, mu, sigma2):\n",
    "    \"\"\"\n",
    "    Computes the probability density function of the multivariate Gaussian distribution.\n",
    "    \"\"\"\n",
    "    n= ? #number of features \n",
    "    sigma_diag=np.diag(sigma2)  #Diagonal matrix (features are independent !!!!)\n",
    "    X = X - mu.T\n",
    "    p = 1/((2*np.pi)**(n/2)*(np.linalg.det(sigma_diag)**0.5))* np.exp(-0.5* np.sum(X @ np.linalg.pinv(sigma_diag) * X,axis=1))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the threshold $\\epsilon$  that will flag an example as anomaly\n",
    "\n",
    "F1 score is used to determine the best parameters i.e best epsilon and best F1 instead of accuracy as the dataset is highly unbalanced. F1 score takes into consideration precision and recall.\n",
    "\n",
    "Precision = true positive/(true positive + false positive)\n",
    "\n",
    "Recall = true positive /(true positive + false negative)\n",
    "\n",
    "F1=2(Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "Best parameters are the ones in which the F1 score value is maximum.\n",
    "\n",
    "Predict anomaly if pval<epsilon that gives a vector of binary values in the variable predictions.\n",
    "\n",
    "Note: We need a try-except block because there can be cases where we divide by zero to calculate precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the function\n",
    "def selectThreshold(yval, pval):\n",
    "    \"\"\"\n",
    "    Find the best threshold (epsilon) to use for selecting outliers\n",
    "    \"\"\"\n",
    "    best_epi = 0\n",
    "    best_F1 = 0\n",
    "    \n",
    "    #range of threshold values to decide the best one. \n",
    "    stepsize = (max(pval) -min(pval))/1000\n",
    "    epi_range = np.arange(pval.min(),pval.max(),stepsize)\n",
    "    for epi in epi_range:\n",
    "        predictions = (pval<epi)[:,np.newaxis]\n",
    "        \n",
    "        #compute true positive (TP)\n",
    "        tp = ?\n",
    "        \n",
    "        #compute false positive (FP)\n",
    "        fp = ?\n",
    "        \n",
    "        #compute false negative \n",
    "        fn = ?      \n",
    "        \n",
    "        try:\n",
    "        # compute precision, recall and F1\n",
    "            prec = ?\n",
    "            \n",
    "            #compute recall and F1\n",
    "            rec = ?\n",
    "            #compute  F1\n",
    "            F1 = ? \n",
    "        \n",
    "            if F1 > best_F1:\n",
    "                best_F1 =F1\n",
    "                best_epi = epi\n",
    "            \n",
    "        except ZeroDivisionError:\n",
    "                print('Warning dividing by zero!!')  \n",
    "        \n",
    "    return best_epi, best_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply multivariateGaussian to compute the probability of the examples in Xval. \n",
    "pval = ?\n",
    "\n",
    "#Apply selectThreshold to compute the best epsilon and best F1 with the validation data\n",
    "epsilon, F1 = ?\n",
    "\n",
    "print(\"Best epsilon found using cross-validation:\",epsilon)  #ANSWER: 0.00018\n",
    "print(\"Best F1 on Cross Validation Set:\",F1)  #ANSWER: 0.8235\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to return the indices of the outliers to identify the faulty servers. This gives us a vector with binary entries where 1 means anomaly and 0 means normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndices(binVec):\n",
    "    l = []\n",
    "    for i in range(len(binVec)):\n",
    "        if binVec[i] == 1:\n",
    "            l.append(i)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply multivariateGaussian to detect abnormal examples (outliers) \n",
    "p = multivariateGaussian(Xtest, mu, sigma2)\n",
    "\n",
    "outl = (p < epsilon)\n",
    "listOfOutliers=findIndices(outl)\n",
    "count_outliers = len(listOfOutliers)\n",
    "print('\\n\\nNumber of outliers (Xtest):', count_outliers)  #ANSWER: 6 \n",
    "print('\\n',listOfOutliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(Xtest[:, 0], Xtest[:, 1], marker = \"x\")\n",
    "plt.xlabel('Latency(ms)')\n",
    "plt.ylabel('Throughput(mb/s)')\n",
    "plt.scatter(Xtest[listOfOutliers,0], Xtest[listOfOutliers, 1], facecolors = 'none', edgecolors = 'r')\n",
    "plt.xlim(-1,30)\n",
    "plt.ylim(-1,30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
